"""
ë„¤ì´ë²„ ìƒí’ˆëª… ìƒì„±ê¸° ì›Œì»¤
ë¹„ë™ê¸° ì‘ì—… ì²˜ë¦¬ ë° ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
"""
from typing import List, Dict, Any, Optional
from PySide6.QtCore import QThread, Signal, QMutex, QMutexLocker
import time

from src.foundation.logging import get_logger
from src.toolbox.progress import calc_percentage

from .models import (
    AnalysisStep, KeywordBasicData, ProductNameData, AIAnalysisResult, GeneratedTitle
)
from .adapters import parse_keywords, collect_product_names_for_keywords

logger = get_logger("features.naver_product_title_generator.worker")


class BasicAnalysisWorker(QThread):
    """2ë‹¨ê³„: ê¸°ì´ˆë¶„ì„ ì›Œì»¤"""
    
    # ì‹œê·¸ë„ ì •ì˜
    progress_updated = Signal(int, str)  # progress%, message
    analysis_completed = Signal(list)    # List[KeywordBasicData]
    error_occurred = Signal(str)         # error_message
    
    def __init__(self, product_name: str):
        super().__init__()
        self.product_name = product_name
        self._stop_requested = False
        self._mutex = QMutex()
    
    def request_stop(self):
        """ì‘ì—… ì¤‘ë‹¨ ìš”ì²­"""
        with QMutexLocker(self._mutex):
            self._stop_requested = True
            
    def stop(self):
        """ì‘ì—… ì¤‘ë‹¨ ìš”ì²­ (í•˜ìœ„ í˜¸í™˜)"""
        self.request_stop()
    
    def is_stopped(self) -> bool:
        """ì¤‘ë‹¨ ìš”ì²­ í™•ì¸"""
        with QMutexLocker(self._mutex):
            return self._stop_requested
    
    def run(self):
        """ì›Œì»¤ ì‹¤í–‰"""
        try:
            logger.info(f"ê¸°ì´ˆë¶„ì„ ì‹œì‘: {self.product_name}")
            
            # 1ë‹¨ê³„: í‚¤ì›Œë“œ íŒŒì‹±
            self.progress_updated.emit(0, "í‚¤ì›Œë“œ íŒŒì‹± ì¤‘...")
            
            if self.is_stopped():
                return
            
            # ì…ë ¥ í…ìŠ¤íŠ¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
            keywords = parse_keywords(self.product_name)
            
            if not keywords:
                self.error_occurred.emit("ë¶„ì„í•  í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            if self.is_stopped():
                return
            
            self.progress_updated.emit(20, f"{len(keywords)}ê°œ í‚¤ì›Œë“œ íŒŒì‹± ì™„ë£Œ")
            
            # 2ë‹¨ê³„: í‚¤ì›Œë“œë³„ ì›”ê²€ìƒ‰ëŸ‰ ë° ì¹´í…Œê³ ë¦¬ ë¶„ì„
            self.progress_updated.emit(30, "ë„¤ì´ë²„ API ë¶„ì„ ì¤‘...")
            
            # í‚¤ì›Œë“œ ì¼ê´„ ë¶„ì„ (ê¸°ì¡´ keyword_analysis ì„œë¹„ìŠ¤ ì‚¬ìš©)
            from src.features.keyword_analysis.service import KeywordAnalysisService
            from src.features.keyword_analysis.models import AnalysisPolicy, AnalysisScope
            from .models import KeywordBasicData
            
            # ì •ì±… ëª…ì‹œì ìœ¼ë¡œ ì„¤ì • (ì „ì²´ ë¶„ì„)
            policy = AnalysisPolicy(scope=AnalysisScope.FULL_ANALYSIS)
            analysis_service = KeywordAnalysisService(policy)
            analyzed_keywords = []
            
            total_keywords = len(keywords)
            for i, keyword in enumerate(keywords):
                if self.is_stopped():
                    return
                
                # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ (30% ~ 90%)
                progress = 30 + int((i / total_keywords) * 60)
                self.progress_updated.emit(progress, f"í‚¤ì›Œë“œ '{keyword}' ë¶„ì„ ì¤‘... ({i+1}/{total_keywords})")
                
                try:
                    kw_data = analysis_service.analyze_single_keyword(keyword)
                    # KeywordDataë¥¼ KeywordBasicDataë¡œ ë³€í™˜ (ì¹´í…Œê³ ë¦¬ëŠ” ì²« ë²ˆì§¸ ì¤„ë§Œ ì‚¬ìš©)
                    category = kw_data.category.split('\n')[0] if kw_data.category else ""
                    basic_data = KeywordBasicData(
                        keyword=kw_data.keyword,
                        search_volume=kw_data.search_volume,
                        category=category
                    )
                    analyzed_keywords.append(basic_data)
                except Exception as e:
                    logger.warning(f"í‚¤ì›Œë“œ '{keyword}' ë¶„ì„ ì‹¤íŒ¨: {e}")
                    # ì‹¤íŒ¨í•œ í‚¤ì›Œë“œë„ í¬í•¨ (ê²€ìƒ‰ëŸ‰ 0)
                    analyzed_keywords.append(KeywordBasicData(
                        keyword=keyword,
                        search_volume=0,
                        category="ë¶„ì„ ì‹¤íŒ¨"
                    ))
            
            if self.is_stopped():
                return
            
            self.progress_updated.emit(90, "í‚¤ì›Œë“œ ë¶„ì„ ì™„ë£Œ")
            
            # ê²€ìƒ‰ëŸ‰ì´ 0ë³´ë‹¤ í° í‚¤ì›Œë“œë§Œ í•„í„°ë§
            valid_keywords = [kw for kw in analyzed_keywords if kw.search_volume > 0]
            
            if not valid_keywords:
                # ê²€ìƒ‰ëŸ‰ì´ ì—†ì–´ë„ ëª¨ë“  í‚¤ì›Œë“œ ë°˜í™˜ (ì‚¬ìš©ìê°€ ì„ íƒí•  ìˆ˜ ìˆë„ë¡)
                valid_keywords = analyzed_keywords
            
            self.progress_updated.emit(100, f"ë¶„ì„ ì™„ë£Œ: {len(valid_keywords)}ê°œ í‚¤ì›Œë“œ")
            
            # ì™„ë£Œ ì‹œê·¸ë„ ë°œì†¡
            self.analysis_completed.emit(valid_keywords)
            
            logger.info(f"ê¸°ì´ˆë¶„ì„ ì™„ë£Œ: {len(valid_keywords)}ê°œ í‚¤ì›Œë“œ")
            
        except Exception as e:
            logger.error(f"ê¸°ì´ˆë¶„ì„ ì‹¤íŒ¨: {e}")
            self.error_occurred.emit(f"ê¸°ì´ˆë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")


class ProductNameCollectionWorker(QThread):
    """2ë‹¨ê³„: ìƒí’ˆëª… ìˆ˜ì§‘ ì›Œì»¤"""
    
    # ì‹œê·¸ë„ ì •ì˜
    progress_updated = Signal(int, str)  # progress%, message
    collection_completed = Signal(list)  # List[Dict] - ìƒí’ˆëª… ë°ì´í„°
    error_occurred = Signal(str)         # error_message
    
    def __init__(self, selected_keywords: List[KeywordBasicData]):
        super().__init__()
        self.selected_keywords = selected_keywords
        self._stop_requested = False
        self._mutex = QMutex()
    
    def request_stop(self):
        """ì‘ì—… ì¤‘ë‹¨ ìš”ì²­"""
        with QMutexLocker(self._mutex):
            self._stop_requested = True
            
    def stop(self):
        """ì‘ì—… ì¤‘ë‹¨ ìš”ì²­ (í•˜ìœ„ í˜¸í™˜)"""
        self.request_stop()
    
    def is_stopped(self) -> bool:
        """ì¤‘ë‹¨ ìš”ì²­ í™•ì¸"""
        with QMutexLocker(self._mutex):
            return self._stop_requested
    
    def run(self):
        """ì›Œì»¤ ì‹¤í–‰"""
        try:
            logger.info(f"ìƒí’ˆëª… ìˆ˜ì§‘ ì‹œì‘: {len(self.selected_keywords)}ê°œ í‚¤ì›Œë“œ")
            
            if not self.selected_keywords:
                self.error_occurred.emit("ì„ íƒëœ í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            # í‚¤ì›Œë“œ ë¬¸ìì—´ ì¶”ì¶œ
            keywords = [kw.keyword for kw in self.selected_keywords]
            
            self.progress_updated.emit(10, f"{len(keywords)}ê°œ í‚¤ì›Œë“œë¡œ ìƒí’ˆëª… ìˆ˜ì§‘ ì‹œì‘...")
            
            if self.is_stopped():
                return
            
            # ê° í‚¤ì›Œë“œë³„ë¡œ ìƒí’ˆëª… ìˆ˜ì§‘ (ì§„í–‰ë¥  ì—…ë°ì´íŠ¸)
            total_keywords = len(keywords)
            collected_data = []
            
            for i, keyword in enumerate(keywords):
                if self.is_stopped():
                    return
                
                progress = 20 + int((i / total_keywords) * 60)  # 20~80%
                self.progress_updated.emit(progress, f"{keyword} ìƒí’ˆëª… ìˆ˜ì§‘ ì¤‘...")
                
                # í‚¤ì›Œë“œë³„ ìƒí’ˆëª… ìˆ˜ì§‘
                try:
                    keyword_products = collect_product_names_for_keywords([keyword], 40)
                    collected_data.extend(keyword_products)
                    
                    # ì§§ì€ ëŒ€ê¸° (API ê³¼ë¶€í•˜ ë°©ì§€)
                    time.sleep(0.2)
                    
                except Exception as e:
                    logger.warning(f"í‚¤ì›Œë“œ {keyword} ìƒí’ˆëª… ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                    continue
                
                if self.is_stopped():
                    return
            
            self.progress_updated.emit(85, "ì¤‘ë³µ ì œê±° ì¤‘...")
            
            if self.is_stopped():
                return
            
            # ì „ì²´ ì¤‘ë³µ ì œê±°
            final_products = collect_product_names_for_keywords(keywords, 40)
            
            self.progress_updated.emit(100, f"ìƒí’ˆëª… ìˆ˜ì§‘ ì™„ë£Œ: {len(final_products)}ê°œ")
            
            # ì™„ë£Œ ì‹œê·¸ë„ ë°œì†¡
            self.collection_completed.emit(final_products)
            
            logger.info(f"ìƒí’ˆëª… ìˆ˜ì§‘ ì™„ë£Œ: {len(final_products)}ê°œ")
            
        except Exception as e:
            logger.error(f"ìƒí’ˆëª… ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            self.error_occurred.emit(f"ìƒí’ˆëª… ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")



class WorkerManager:
    """ì›Œì»¤ ê´€ë¦¬ì"""
    
    def __init__(self):
        self.current_worker: Optional[QThread] = None
        self.worker_history = []
    
    def start_worker(self, worker: QThread) -> bool:
        """ìƒˆ ì›Œì»¤ ì‹œì‘"""
        try:
            # ê¸°ì¡´ ì›Œì»¤ê°€ ìˆìœ¼ë©´ ì •ë¦¬
            self.stop_current_worker()
            
            # ìƒˆ ì›Œì»¤ ì‹œì‘
            self.current_worker = worker
            self.worker_history.append(worker)
            worker.start()
            
            logger.info(f"ì›Œì»¤ ì‹œì‘: {worker.__class__.__name__}")
            return True
            
        except Exception as e:
            logger.error(f"ì›Œì»¤ ì‹œì‘ ì‹¤íŒ¨: {e}")
            return False
    
    def stop_current_worker(self) -> bool:
        """í˜„ì¬ ì›Œì»¤ ì¤‘ë‹¨"""
        if self.current_worker and self.current_worker.isRunning():
            try:
                # ì›Œì»¤ì— ì¤‘ë‹¨ ìš”ì²­
                if hasattr(self.current_worker, 'stop'):
                    self.current_worker.stop()
                
                # ìµœëŒ€ 5ì´ˆ ëŒ€ê¸°
                if not self.current_worker.wait(5000):
                    logger.warning("ì›Œì»¤ê°€ 5ì´ˆ ë‚´ì— ì¢…ë£Œë˜ì§€ ì•ŠìŒ, ê°•ì œ ì¢…ë£Œ")
                    self.current_worker.terminate()
                    self.current_worker.wait(2000)
                
                logger.info(f"ì›Œì»¤ ì¤‘ë‹¨ ì™„ë£Œ: {self.current_worker.__class__.__name__}")
                return True
                
            except Exception as e:
                logger.error(f"ì›Œì»¤ ì¤‘ë‹¨ ì‹¤íŒ¨: {e}")
                return False
        
        return True
        
    def stop_worker(self, worker: QThread) -> bool:
        """íŠ¹ì • ì›Œì»¤ ì¤‘ë‹¨"""
        if worker and worker.isRunning():
            try:
                # ì›Œì»¤ì— ì¤‘ë‹¨ ìš”ì²­
                if hasattr(worker, 'request_stop'):
                    worker.request_stop()
                elif hasattr(worker, 'stop'):
                    worker.stop()
                
                # ìµœëŒ€ 3ì´ˆ ëŒ€ê¸°
                if not worker.wait(3000):
                    logger.warning(f"ì›Œì»¤ê°€ 3ì´ˆ ë‚´ì— ì¢…ë£Œë˜ì§€ ì•ŠìŒ: {worker.__class__.__name__}")
                    worker.terminate()
                    worker.wait(1000)
                
                logger.info(f"ì›Œì»¤ ì¤‘ë‹¨ ì™„ë£Œ: {worker.__class__.__name__}")
                return True
                
            except Exception as e:
                logger.error(f"ì›Œì»¤ ì¤‘ë‹¨ ì‹¤íŒ¨: {e}")
                return False
        
        return True
    
    def cleanup_all_workers(self):
        """ëª¨ë“  ì›Œì»¤ ì •ë¦¬"""
        self.stop_current_worker()
        
        # íˆìŠ¤í† ë¦¬ì˜ ëª¨ë“  ì›Œì»¤ë“¤ë„ ì •ë¦¬
        for worker in self.worker_history:
            if worker.isRunning():
                try:
                    if hasattr(worker, 'stop'):
                        worker.stop()
                    worker.wait(2000)
                except:
                    pass
        
        self.worker_history.clear()
        self.current_worker = None
        
        logger.info("ëª¨ë“  ì›Œì»¤ ì •ë¦¬ ì™„ë£Œ")
    
    def is_working(self) -> bool:
        """í˜„ì¬ ì‘ì—… ì¤‘ì¸ì§€ í™•ì¸"""
        return self.current_worker is not None and self.current_worker.isRunning()


class AIAnalysisWorker(QThread):
    """3ë‹¨ê³„: AI í‚¤ì›Œë“œ ë¶„ì„ ì›Œì»¤"""
    
    # ì‹œê·¸ë„ ì •ì˜
    progress_updated = Signal(int, str)  # progress%, message
    analysis_completed = Signal(list)    # List[KeywordBasicData] - AI ë¶„ì„ ê²°ê³¼
    analysis_data_updated = Signal(dict) # ì‹¤ì‹œê°„ ë¶„ì„ ë°ì´í„° ì—…ë°ì´íŠ¸
    error_occurred = Signal(str)         # error_message
    
    def __init__(self, product_names: List[str], prompt: str):
        super().__init__()
        self.product_names = product_names
        self.prompt = prompt
        self._stop_requested = False
        self._mutex = QMutex()
    
    def request_stop(self):
        """ì‘ì—… ì¤‘ë‹¨ ìš”ì²­"""
        with QMutexLocker(self._mutex):
            self._stop_requested = True
            
    def stop(self):
        """ì‘ì—… ì¤‘ë‹¨ ìš”ì²­ (í•˜ìœ„ í˜¸í™˜)"""
        self.request_stop()
    
    def is_stopped(self) -> bool:
        """ì¤‘ë‹¨ ìš”ì²­ í™•ì¸"""
        with QMutexLocker(self._mutex):
            return self._stop_requested
    
    def run(self):
        """ì›Œì»¤ ì‹¤í–‰"""
        try:
            logger.info(f"AI ë¶„ì„ ì‹œì‘")
            
            # 1ë‹¨ê³„: AI API í˜¸ì¶œ
            self.progress_updated.emit(10, "AI ëª¨ë¸ì— ë¶„ì„ ìš”ì²­ ì¤‘...")
            
            if self.is_stopped():
                return
            
            # í”„ë¡¬í”„íŠ¸ ìƒì„± (ìƒí’ˆëª… + ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ ê²°í•©)
            from .engine_local import build_ai_prompt
            
            # ìƒí’ˆëª…ì—ì„œ title ì¶”ì¶œ
            product_titles = []
            for product in self.product_names:
                if isinstance(product, dict):
                    product_titles.append(product.get('title', ''))
                elif isinstance(product, str):
                    product_titles.append(product)
            
            final_prompt = build_ai_prompt(product_titles, self.prompt)
            
            # ì„¤ì •ëœ AI API í˜¸ì¶œ
            ai_response = self.call_ai_api(final_prompt)
            
            # AI ì‘ë‹µ ë°ì´í„° ì—…ë°ì´íŠ¸
            self.analysis_data_updated.emit({
                'input_prompt': final_prompt,
                'ai_response': ai_response
            })
            
            if self.is_stopped():
                return
            
            self.progress_updated.emit(50, "AI ì‘ë‹µ í‚¤ì›Œë“œ ì¶”ì¶œ ì¤‘...")
            
            # 2ë‹¨ê³„: AI ì‘ë‹µì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
            from .engine_local import parse_ai_keywords_response, deduplicate_keywords
            extracted_keywords = parse_ai_keywords_response(ai_response)
            
            if not extracted_keywords:
                self.error_occurred.emit("AIì—ì„œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                return
            
            self.progress_updated.emit(60, f"í‚¤ì›Œë“œ ì¤‘ë³µ ì œê±° ì¤‘... ({len(extracted_keywords)}ê°œ)")
            
            # 3ë‹¨ê³„: í‚¤ì›Œë“œ ì¤‘ë³µ ì œê±° ("ê°•ì•„ì§€ê°„ì‹" = "ê°•ì•„ì§€ ê°„ì‹")
            unique_keywords = deduplicate_keywords(extracted_keywords)
            
            if self.is_stopped():
                return
            
            self.progress_updated.emit(70, f"{len(unique_keywords)}ê°œ í‚¤ì›Œë“œ ì›”ê²€ìƒ‰ëŸ‰ ì¡°íšŒ ì¤‘...")
            
            # 4ë‹¨ê³„: ì›”ê²€ìƒ‰ëŸ‰ ì¡°íšŒ (ê¸°ì¡´ keyword_analysis ì„œë¹„ìŠ¤ ì‚¬ìš©)
            logger.info(f"ğŸ“Š ì›”ê²€ìƒ‰ëŸ‰ ì¡°íšŒí•  í‚¤ì›Œë“œë“¤: {unique_keywords[:10]}...")  # ì²˜ìŒ 10ê°œë§Œ ë¡œê·¸
            
            # ê¸°ì¡´ì— ì˜ ì‘ë™í•˜ë˜ keyword_analysis ì„œë¹„ìŠ¤ ì‚¬ìš©
            from src.features.keyword_analysis.service import KeywordAnalysisService
            from src.features.keyword_analysis.models import AnalysisPolicy, AnalysisScope
            from .models import KeywordBasicData
            
            # ì •ì±… ëª…ì‹œì ìœ¼ë¡œ ì„¤ì • (ì „ì²´ ë¶„ì„)
            policy = AnalysisPolicy(scope=AnalysisScope.FULL_ANALYSIS)
            analysis_service = KeywordAnalysisService(policy)
            analyzed_keywords = []
            
            logger.info(f"ì •ì±… ì„¤ì •: ê²½ìŸë¶„ì„={policy.should_analyze_competition()}, ì¹´í…Œê³ ë¦¬ë¶„ì„={policy.should_analyze_category()}")
            
            total_keywords = len(unique_keywords)
            for i, keyword in enumerate(unique_keywords):
                if self.is_stopped():
                    return
                
                # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ (0% ~ 85%)
                progress = int((i / total_keywords) * 85)  
                self.progress_updated.emit(progress, f"í‚¤ì›Œë“œ '{keyword}' ë¶„ì„ ì¤‘... ({i+1}/{total_keywords})")
                
                try:
                    logger.info(f"ğŸ” í‚¤ì›Œë“œ ë¶„ì„ ì‹œì‘: '{keyword}' ({i+1}/{total_keywords})")
                    kw_data = analysis_service.analyze_single_keyword(keyword)
                    
                    # KeywordDataë¥¼ KeywordBasicDataë¡œ ë³€í™˜ (ì¹´í…Œê³ ë¦¬ëŠ” ì²« ë²ˆì§¸ ì¤„ë§Œ ì‚¬ìš©)
                    category = kw_data.category.split('\n')[0] if kw_data.category else ""
                    basic_data = KeywordBasicData(
                        keyword=kw_data.keyword,
                        search_volume=kw_data.search_volume,
                        category=category
                    )
                    analyzed_keywords.append(basic_data)
                    
                    if kw_data.search_volume and kw_data.search_volume > 0:
                        logger.info(f"âœ… '{keyword}' ë¶„ì„ ì™„ë£Œ: ì›”ê²€ìƒ‰ëŸ‰ {kw_data.search_volume}")
                    else:
                        logger.debug(f"âŒ '{keyword}' ë¶„ì„ ì™„ë£Œ: ì›”ê²€ìƒ‰ëŸ‰ 0")
                        
                except Exception as e:
                    logger.error(f"âŒ í‚¤ì›Œë“œ '{keyword}' ë¶„ì„ ì‹¤íŒ¨: {e}")
                    # ì‹¤íŒ¨í•œ í‚¤ì›Œë“œë„ í¬í•¨ (ê²€ìƒ‰ëŸ‰ 0)
                    analyzed_keywords.append(KeywordBasicData(
                        keyword=keyword,
                        search_volume=0,
                        category="ë¶„ì„ ì‹¤íŒ¨"
                    ))
            
            logger.info(f"ğŸ“Š ì›”ê²€ìƒ‰ëŸ‰ ì¡°íšŒ ì™„ë£Œ: {len(analyzed_keywords)}ê°œ ì¤‘ ê²€ìƒ‰ëŸ‰ ìˆëŠ” í‚¤ì›Œë“œ {len([kw for kw in analyzed_keywords if kw.search_volume > 0])}ê°œ")
            
            # ë¶„ì„ ë°ì´í„° ì—…ë°ì´íŠ¸ (ì›”ê²€ìƒ‰ëŸ‰ ì¡°íšŒ ê²°ê³¼)
            self.analysis_data_updated.emit({
                'analyzed_keywords': analyzed_keywords,
                'extracted_keywords': unique_keywords
            })
            
            if self.is_stopped():
                return
            
            self.progress_updated.emit(85, "ì›”ê²€ìƒ‰ëŸ‰ 100 ì´ìƒ í‚¤ì›Œë“œ í•„í„°ë§ ì¤‘...")
            
            # 5ë‹¨ê³„: ì›”ê²€ìƒ‰ëŸ‰ 100 ì´ìƒ í•„í„°ë§
            from .engine_local import filter_keywords_by_search_volume
            volume_filtered = filter_keywords_by_search_volume(analyzed_keywords, 100)
            
            if not volume_filtered:
                self.error_occurred.emit("ì›”ê²€ìƒ‰ëŸ‰ 100 ì´ìƒì¸ í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            self.progress_updated.emit(95, f"{len(volume_filtered)}ê°œ í‚¤ì›Œë“œ ì¹´í…Œê³ ë¦¬ ì¡°íšŒ ì¤‘...")
            
            # 6ë‹¨ê³„: ì¹´í…Œê³ ë¦¬ ì •ë³´ ë³´ê°• (100 ì´ìƒ í‚¤ì›Œë“œë§Œ)
            # TODO: ì—¬ê¸°ì— ì¹´í…Œê³ ë¦¬ ì¡°íšŒ ë¡œì§ ì¶”ê°€ ì˜ˆì •
            filtered_keywords = volume_filtered
            
            # ìµœì¢… ë¶„ì„ ë°ì´í„° ì—…ë°ì´íŠ¸
            self.analysis_data_updated.emit({
                'filtered_keywords': filtered_keywords
            })
            
            self.progress_updated.emit(100, f"AI ë¶„ì„ ì™„ë£Œ: {len(filtered_keywords)}ê°œ í‚¤ì›Œë“œ")
            
            # ì™„ë£Œ ì‹œê·¸ë„ ë°œì†¡
            self.analysis_completed.emit(filtered_keywords)
            
            logger.info(f"AI ë¶„ì„ ì™„ë£Œ: {len(filtered_keywords)}ê°œ í‚¤ì›Œë“œ")
            
        except Exception as e:
            logger.error(f"AI ë¶„ì„ ì‹¤íŒ¨: {e}")
            self.error_occurred.emit(f"AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
    
    def call_ai_api(self, prompt: str) -> str:
        """ì‚¬ìš©ìê°€ ì„¤ì •í•œ AI API í˜¸ì¶œ"""
        try:
            from src.foundation.config import config_manager
            api_config = config_manager.load_api_config()
            
            # í˜„ì¬ ì„ íƒëœ AI ëª¨ë¸ í™•ì¸
            current_model = getattr(api_config, 'current_ai_model', '')
            if not current_model or current_model == "AI ì œê³µìë¥¼ ì„ íƒí•˜ì„¸ìš”":
                raise Exception("AI ëª¨ë¸ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì„¤ì • ë©”ë‰´ì—ì„œ AI ëª¨ë¸ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
            
            # ì„ íƒëœ ëª¨ë¸ì— ë”°ë¼ ì ì ˆí•œ API í˜¸ì¶œ
            if "GPT" in current_model:
                if not hasattr(api_config, 'openai_api_key') or not api_config.openai_api_key:
                    raise Exception("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                logger.info(f"{current_model}ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¶„ì„í•©ë‹ˆë‹¤.")
                return self.call_openai_direct(prompt, api_config.openai_api_key, current_model)
                
            elif "Gemini" in current_model:
                if not hasattr(api_config, 'gemini_api_key') or not api_config.gemini_api_key:
                    raise Exception("Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                logger.info(f"{current_model}ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¶„ì„í•©ë‹ˆë‹¤.")
                return self.call_gemini_direct(prompt, api_config.gemini_api_key, current_model)
                
            elif "Claude" in current_model:
                if not hasattr(api_config, 'claude_api_key') or not api_config.claude_api_key:
                    raise Exception("Claude API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                logger.info(f"{current_model}ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¶„ì„í•©ë‹ˆë‹¤.")
                return self.call_claude_direct(prompt, api_config.claude_api_key, current_model)
            else:
                raise Exception(f"ì§€ì›ë˜ì§€ ì•ŠëŠ” AI ëª¨ë¸ì…ë‹ˆë‹¤: {current_model}")
                
        except Exception as e:
            logger.error(f"AI API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            raise Exception(f"AI ë¶„ì„ ì‹¤íŒ¨: {e}")
    
    def call_openai_direct(self, prompt: str, api_key: str, model_name: str) -> str:
        """OpenAI API ì§ì ‘ í˜¸ì¶œ"""
        import requests
        
        try:
            headers = {
                'Authorization': f'Bearer {api_key}',
                'Content-Type': 'application/json'
            }
            
            # ì„ íƒëœ ëª¨ë¸ì— ë”°ë¼ ì‹¤ì œ ëª¨ë¸ ID ì„¤ì •
            if "GPT-4o Mini" in model_name:
                model_id = "gpt-4o-mini"
                max_tokens = 16384
            elif "GPT-4o" in model_name and "Mini" not in model_name:
                model_id = "gpt-4o"
                max_tokens = 8192
            elif "GPT-4 Turbo" in model_name:
                model_id = "gpt-4-turbo"
                max_tokens = 8192
            else:
                model_id = "gpt-4o-mini"  # ê¸°ë³¸ê°’
                max_tokens = 16384
            
            payload = {
                "model": model_id,
                "messages": [{"role": "user", "content": prompt}],
                "max_tokens": max_tokens,
                "temperature": 0.3
            }
            
            response = requests.post(
                'https://api.openai.com/v1/chat/completions',
                headers=headers,
                json=payload,
                timeout=60
            )
            
            if response.status_code == 200:
                data = response.json()
                if 'choices' in data and len(data['choices']) > 0:
                    return data['choices'][0]['message']['content']
                else:
                    raise Exception("OpenAI API ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            else:
                raise Exception(f"OpenAI API ì˜¤ë¥˜: {response.status_code} - {response.text}")
                
        except Exception as e:
            logger.error(f"OpenAI API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            raise Exception(f"OpenAI API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
    
    def call_gemini_direct(self, prompt: str, api_key: str, model_name: str) -> str:
        """Gemini API ì§ì ‘ í˜¸ì¶œ"""
        import requests
        
        try:
            headers = {
                'Content-Type': 'application/json'
            }
            
            # ì„ íƒëœ ëª¨ë¸ì— ë”°ë¼ ì‹¤ì œ ëª¨ë¸ ID ì„¤ì •
            if "Gemini 1.5 Flash" in model_name:
                model_id = "gemini-1.5-flash-latest"
                max_tokens = 8192
            elif "Gemini 1.5 Pro" in model_name:
                model_id = "gemini-1.5-pro-latest"
                max_tokens = 8192
            elif "Gemini 2.0 Flash" in model_name:
                model_id = "gemini-2.0-flash-exp"
                max_tokens = 8192
            else:
                model_id = "gemini-1.5-flash-latest"  # ê¸°ë³¸ê°’
                max_tokens = 8192
            
            payload = {
                "contents": [{
                    "parts": [{"text": prompt}]
                }],
                "generationConfig": {
                    "temperature": 0.3,
                    "maxOutputTokens": max_tokens
                }
            }
            
            url = f'https://generativelanguage.googleapis.com/v1beta/models/{model_id}:generateContent?key={api_key}'
            
            response = requests.post(
                url,
                headers=headers,
                json=payload,
                timeout=60
            )
            
            if response.status_code == 200:
                data = response.json()
                if 'candidates' in data and len(data['candidates']) > 0:
                    content = data['candidates'][0].get('content', {})
                    parts = content.get('parts', [])
                    if parts:
                        return parts[0].get('text', '')
                    else:
                        raise Exception("Gemini API ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
                else:
                    raise Exception("Gemini API ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            else:
                raise Exception(f"Gemini API ì˜¤ë¥˜: {response.status_code} - {response.text}")
                
        except Exception as e:
            logger.error(f"Gemini API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            raise Exception(f"Gemini API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
    
    def call_claude_direct(self, prompt: str, api_key: str, model_name: str) -> str:
        """Claude API ì§ì ‘ í˜¸ì¶œ"""
        import requests
        
        try:
            headers = {
                'x-api-key': api_key,
                'Content-Type': 'application/json',
                'anthropic-version': '2023-06-01'
            }
            
            # ì„ íƒëœ ëª¨ë¸ì— ë”°ë¼ ì‹¤ì œ ëª¨ë¸ ID ì„¤ì •
            if "Claude 3.5 Sonnet" in model_name:
                model_id = "claude-3-5-sonnet-20241022"
                max_tokens = 8192
            elif "Claude 3.5 Haiku" in model_name:
                model_id = "claude-3-5-haiku-20241022"
                max_tokens = 8192
            elif "Claude 3 Opus" in model_name:
                model_id = "claude-3-opus-20240229"
                max_tokens = 8192
            else:
                model_id = "claude-3-5-sonnet-20241022"  # ê¸°ë³¸ê°’
                max_tokens = 8192
            
            payload = {
                "model": model_id,
                "max_tokens": max_tokens,
                "temperature": 0.3,
                "messages": [{"role": "user", "content": prompt}]
            }
            
            response = requests.post(
                'https://api.anthropic.com/v1/messages',
                headers=headers,
                json=payload,
                timeout=60
            )
            
            if response.status_code == 200:
                data = response.json()
                if 'content' in data and len(data['content']) > 0:
                    return data['content'][0]['text']
                else:
                    raise Exception("Claude API ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            else:
                raise Exception(f"Claude API ì˜¤ë¥˜: {response.status_code} - {response.text}")
                
        except Exception as e:
            logger.error(f"Claude API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            raise Exception(f"Claude API í˜¸ì¶œ ì‹¤íŒ¨: {e}")


# ì „ì—­ ì›Œì»¤ ë§¤ë‹ˆì €
worker_manager = WorkerManager()