"""
ë„¤ì´ë²„ ìƒí’ˆëª… ìƒì„±ê¸° ë¡œì»¬ ì—”ì§„
ìˆœìˆ˜ í•¨ìˆ˜ ê¸°ë°˜ í•µì‹¬ ì•Œê³ ë¦¬ì¦˜ (I/O ì—†ìŒ)
"""
from typing import List, Dict, Any, Optional
import re
import math
from collections import Counter

from .models import KeywordBasicData, GeneratedTitle


# AI í”„ë¡¬í”„íŠ¸ ì‹œìŠ¤í…œ (ê³µìš© - ëª¨ë“  í”„ë¡¬í”„íŠ¸ì— ìë™ ì¶”ê°€)
SYSTEM_PROMPT = """ë‹¹ì‹ ì€ ë„¤ì´ë²„ ì‡¼í•‘ ìƒí’ˆëª… ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.  
ì•„ë˜ ìƒí’ˆëª…ì„ ë¶„ì„í•´, ì‚¬ëŒë“¤ì´ ì‹¤ì œ ê²€ìƒ‰í•  ê°€ëŠ¥ì„±ì´ ë†’ì€ í‚¤ì›Œë“œë¥¼ ëŒ€ëŸ‰ ìƒì„±í•˜ì„¸ìš”.  
ê²°ê³¼ëŠ” ë„¤ì´ë²„ ì›”ê°„ ê²€ìƒ‰ëŸ‰ API ë¹„êµìš©ì´ë©°, ëª¨ë“  ì¹´í…Œê³ ë¦¬ì— ê³µìš©ìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥í•´ì•¼ í•©ë‹ˆë‹¤.

ğŸ”¸ í•„ìˆ˜ ì¶œë ¥ í˜•ì‹ (ì‚¬ìš©ì ê·œì¹™ê³¼ ìƒê´€ì—†ì´ ë°˜ë“œì‹œ ì¤€ìˆ˜)
- í‚¤ì›Œë“œë§Œ ì‰¼í‘œ(,)ë¡œ êµ¬ë¶„í•˜ì—¬ í•œ ì¤„ì— ì¶œë ¥
- ì„¤ëª…/ë¨¸ë¦¬ë§/ì½”ë“œë¸”ë¡ ê¸ˆì§€.
- ê° í‚¤ì›Œë“œëŠ” **2~15ì**, **ìµœëŒ€ 3ì–´ì ˆ**, **ë°”ì´ê·¸ë¨/íŠ¸ë¼ì´ê·¸ë¨ì€ ì•µì»¤ í¬í•¨ í•„ìˆ˜**.
- single + bigram + trigram í•©ì‚° 300ê°œ ì´ìƒì˜ í‚¤ì›Œë“œ ìƒì„±
- ì¡°ê±´ ë¯¸ë‹¬ ì‹œ ê°œìˆ˜ í™•ë³´ ìœ„í•´ ê·œì¹™ ì™„í™” ê°€ëŠ¥.

[ìì²´ ì ê²€(ì¶œë ¥ ì§ì „)]
- [ ] ì„ ë‘ ë¸Œëœë“œ/ê´„í˜¸ ë¸”ë¡ ì œê±°ë¨?
- [ ] í”„ë¡œëª¨ì…˜/í¬ì¥/ìˆ˜ëŸ‰/ê´‘ê³ ì„±/ì¸ì¦ í‘œê¸° ì œê±°ë¨?
- [ ] **ì•µì»¤ ë¯¸í¬í•¨ í‚¤ì›Œë“œ 0ê°œ**?
- [ ] ëŒ€ìƒ ì¼ë°˜ì–´ ë‹¨ë… í‚¤ì›Œë“œ 0ê°œ?
- [ ] ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ ì–´ìˆœ?"""

# ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ë‚´ìš© (ì‚¬ìš©ìì—ê²Œ í‘œì‹œìš©)
DEFAULT_AI_PROMPT = """[ê·œì¹™]

1. ë¸Œëœë“œëª… ì œê±°  
- ëª¨ë“  ë¸Œëœë“œëª… ì‚­ì œ
- ìƒí’ˆëª… **ì„ ë‘ 1~3ì–´ì ˆ**ì€ ë¸Œëœë“œì¼ í™•ë¥ ì´ ë†’ìœ¼ë¯€ë¡œ ìš°ì„  ì œê±°.
- ë‹¨, ì„ ë‘ í† í°ì´ â€˜ì¼ë°˜ ì œí’ˆëª…/í˜•íƒœ/ì¬ë£Œ/íŠ¹ì§• í•µì‹¬ ì§‘í•©â€™ì´ë©´ ì œê±°í•˜ì§€ ì•ŠìŒ.

2. ë‹¨ìœ„Â·ìš©ëŸ‰Â·ìˆ˜ì¹˜ ì œê±°  
- g, kg, ml, ê°œ, ê°œì…, ë°•ìŠ¤, ì„¸íŠ¸, %, p, S, M, L, ì†Œí˜•, ì¤‘í˜•, ëŒ€í˜• ë“± ì œì™¸.  

3. ê´‘ê³ ì„±Â·ê³¼ì¥ì–´ ì œê±°
- ì¸ê¸°, íŠ¹ê°€, ì‹ ìƒ, í• ì¸, ë¬´ë£Œë°°ì†¡, ë©‹ì§„, ì´ìœ, ì„¸ë ¨ëœ, ê°€ì„±ë¹„, ì¶”ì²œ ì™€ ê°™ì€ ì£¼ê´€ì ì¸ ë‹¨ì–´, ì œí’ˆì„ ê¾¸ë©°ì£¼ëŠ” ë‹¨ì–´ ì œì™¸.  

4. ì¸ì¦/ê¸°ê´€ì–´(HACCP ë“±) ì œê±°
- HACCP, êµ­ë‚´ì‚°, êµ­ë‚´ìƒì‚°, ì˜¤ë¦¬ì§€ë„ ë“±(ì¹´í…Œê³ ë¦¬ íŒë³„ ê¸°ì—¬ ë‚®ìŒ).

5. ì¹´í…Œê³ ë¦¬ ì•µì»¤(ì œí’ˆ í•µì‹¬ëª…ì‚¬) ì¶”ì¶œ
- ì…ë ¥ ìƒí’ˆëª… ì „ì²´ì—ì„œ **ì œí’ˆì„ ì§ì ‘ ê°€ë¦¬í‚¤ëŠ” ì¼ë°˜ëª…/í˜•íƒœ/íƒ€ì… ëª…ì‚¬**(ì˜ˆ: ë´íƒˆê»Œ, ì–‘ì¹˜ê»Œ, ê°œê»Œ, ìŠ¤í‹±, ë§, ë³¸, ìŠ¤íŠ¸ë¦½ / ë…¸íŠ¸ë¶, ì´ì–´í°, ê°€ë°© / ìƒ´í‘¸, ì¹˜ì•½ ë“±)ë¥¼ ì¶”ì¶œí•˜ê³ ,
- ë¹ˆë„Â·ê²°í•© íŒ¨í„´ì„ ê·¼ê±°ë¡œ **ìƒìœ„ ì•µì»¤ í† í° ì§‘í•©**ì„ ë§Œë“­ë‹ˆë‹¤(ë™ì‚¬Â·í˜•ìš©ì‚¬Â·ë¸Œëœë“œÂ·í”„ë¡œëª¨ì…˜Â·ìˆ˜ëŸ‰ í† í° ì œì™¸).

6. ëŒ€ìƒ ì¼ë°˜ì–´ ì·¨ê¸‰(ì¤‘ìš”)
- **â€˜ê°•ì•„ì§€/ì• ê²¬/ë°˜ë ¤ê²¬/ì—¬ì„±/ë‚¨ì„±/ìœ ì•„/ì•„ê¸°â€™ ë“± ëŒ€ìƒ ì¼ë°˜ì–´ëŠ” â€˜ë‹¨ë… í‚¤ì›Œë“œ ê¸ˆì§€â€™.**
- ë˜í•œ **ì•µì»¤ ì—†ëŠ” ì¡°í•©ì—ì„œ ëŒ€ìƒ ì¼ë°˜ì–´ ì‚¬ìš© ê¸ˆì§€**.
- í•„ìš” ì‹œ ë„ë©”ì¸ì— ë”°ë¼ ì˜ë¯¸ ë¶„ë³„ì— ë„ì›€ì„ ì¤„ ë•Œì—ë§Œ **ì•µì»¤ì™€ ê²°í•©ëœ ì¡°í•©**ìœ¼ë¡œ ì œí•œì ìœ¼ë¡œ í—ˆìš©(ì˜ˆ: â€œì–‘ì¹˜ê»Œâ€ì´ ì•µì»¤ì¼ ë•Œ â€œë°˜ë ¤ê²¬ ì–‘ì¹˜ê»Œâ€ ê°€ëŠ¥). ê¸°ë³¸ê°’ì€ **ë¶ˆí—ˆ**.
  - ALLOW_AUDIENCE_SINGLE={{false}}  # ë‹¨ë… ê¸ˆì§€
  - ALLOW_AUDIENCE_IN_COMBOS={{false}}  # ì¡°í•©ì—ì„œë„ ê¸°ë³¸ ê¸ˆì§€

7. í‚¤ì›Œë“œ ìƒì„± ê·œì¹™
1) ì‹±ê¸€(single_keywords)
   - **ì•µì»¤ ê·¸ ìì²´**(í˜¹ì€ ì¹´í…Œê³ ë¦¬ë¥¼ ê°•í•˜ê²Œ ì‹œì‚¬í•˜ëŠ” ì¬ë£ŒÂ·í˜•íƒœ ë‹¨ì¼ì–´)ë§Œ í—ˆìš©.
   - ëŒ€ìƒ ì¼ë°˜ì–´ ë‹¨ë… ê¸ˆì§€, ë¸Œëœë“œ/ëª°ëª…/ì¸í”Œë£¨ì–¸ì„œëª… ê¸ˆì§€, ì˜ë¯¸ ë¶ˆëª… ê¸ˆì§€.

2) ë°”ì´ê·¸ë¨(bigram_keywords)
   - ì„œë¡œ ë‹¤ë¥¸ ì¶• 2ê°œ ì¡°í•©: **(íŠ¹ì§•â†’ì•µì»¤), (í˜•íƒœâ†’ì•µì»¤), (ì¬ë£Œâ†’ì•µì»¤), (ìŠ¤í™â†’ì•µì»¤), (í˜¸í™˜â†’ì•µì»¤)** ë“±.
   - ì˜ˆ) â€œì¹˜ì„ì œê±° ë´íƒˆê»Œâ€, â€œë¡œìš°í•˜ì´ë“œ ê°œê»Œâ€, â€œì¹ ë©´ì¡°í˜ì¤„ ì¸„â€, â€œí—¤íŒŒí•„í„° ê³µê¸°ì²­ì •ê¸°â€, â€œ16ì¸ì¹˜ ë…¸íŠ¸ë¶â€
   - ëŒ€ìƒ ì¼ë°˜ì–´ëŠ” ê¸°ë³¸ ê¸ˆì§€(ALLOW_AUDIENCE_IN_COMBOS=false).

3) íŠ¸ë¼ì´ê·¸ë¨(trigram_keywords)
   - ì„œë¡œ ë‹¤ë¥¸ ì¶• 3ê°œ ì¡°í•© + **ì•µì»¤ í¬í•¨ í•„ìˆ˜**, ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ ì–´ìˆœ.
   - ì˜ˆ) â€œì…ëƒ„ìƒˆ ì œê±° ì–‘ì¹˜ê»Œâ€, â€œì €ì•ŒëŸ¬ì§€ í„°í‚¤ì¸„ ìŠ¤í‹±â€, â€œê²Œì´ë° 16ì¸ì¹˜ ë…¸íŠ¸ë¶â€, â€œì—¬ë¦„ìš© ë‚¨ì„± ë“±ì‚°í™”â€(â€» ëŒ€ìƒì–´ í—ˆìš© ì‹œì—ë§Œ)

4) í’ˆì§ˆ ê°€ë“œ
   - ë¸Œëœë“œ í¬í•¨/ìˆ«ì ë‚˜ì—´/ì½”ë“œí˜•/ë‚œì‚½Â·ë¹„ë¬¸/ì•µì»¤ ë¯¸í¬í•¨ ì¡°í•© ì œê±°.
   - 4ì–´ì ˆ ì´ìƒ ì¡°í•© ê¸ˆì§€.
   - ë™ì¼ ì˜ë¯¸ ë³€í˜•(ë„ì–´ì“°ê¸°/í•˜ì´í”ˆ/ëŒ€ì†Œë¬¸ ì°¨ì´)ì€ 1ê°œë§Œ ìœ ì§€.
   - **ëª¨ë“  í‚¤ì›Œë“œëŠ” ìµœì¢…ì ìœ¼ë¡œ ì•µì»¤ ë§¤í•‘ì´ ê°€ëŠ¥í•œì§€** ìì²´ ì ê²€."""



def extract_keywords_from_product_name(product_name: str) -> List[str]:
    """ì œí’ˆëª…ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ (ì•ìœ¼ë¡œ ì‚¬ìš©í•  í•¨ìˆ˜)"""
    # í•œê¸€, ì˜ì–´, ìˆ«ìë§Œ ë‚¨ê¸°ê³  ì •ë¦¬
    cleaned = re.sub(r'[^\w\sê°€-í£]', ' ', product_name)
    
    keywords = set()
    words = cleaned.split()
    
    # 1. ê°œë³„ ë‹¨ì–´ë“¤
    for word in words:
        if len(word) >= 2:
            keywords.add(word.lower())
    
    # 2. 2ê¸€ì ì¡°í•©
    if len(words) > 1:
        for i in range(len(words) - 1):
            combined = f"{words[i]} {words[i+1]}".lower()
            keywords.add(combined)
    
    # 3. ì „ì²´ ì¡°í•©
    if len(words) <= 3:  # 3ë‹¨ì–´ ì´í•˜ì¼ ë•Œë§Œ
        keywords.add(product_name.lower())
    
    return list(keywords)


def calculate_seo_score(title: str, keywords: List[str]) -> float:
    """SEO ì ìˆ˜ ê³„ì‚° (ì•ìœ¼ë¡œ ì‚¬ìš©í•  í•¨ìˆ˜)"""
    score = 50.0  # ê¸°ë³¸ ì ìˆ˜
    
    # í‚¤ì›Œë“œ í¬í•¨ë„
    for keyword in keywords:
        if keyword.lower() in title.lower():
            score += 10
    
    # ê¸¸ì´ ì ì •ì„±
    length = len(title)
    if 20 <= length <= 40:
        score += 20
    elif length < 20:
        score -= 10
    elif length > 50:
        score -= 15
    
    return min(score, 100.0)


def generate_title_variations(keywords: List[str], original_product: str) -> List[str]:
    """í‚¤ì›Œë“œ ì¡°í•©ìœ¼ë¡œ ìƒí’ˆëª… ë³€í˜• ìƒì„± (ì•ìœ¼ë¡œ êµ¬í˜„í•  í•¨ìˆ˜)"""
    variations = set()
    
    # ê¸°ë³¸ íŒ¨í„´ë“¤
    patterns = [
        "{product} {keyword}",
        "{keyword} {product}",
        "{product} {keyword} ì¶”ì²œ",
        "{keyword} ì „ë¬¸ {product}",
        "ì¸ê¸° {keyword} {product}"
    ]
    
    # ê° í‚¤ì›Œë“œì™€ íŒ¨í„´ ì¡°í•©
    for keyword in keywords[:5]:  # ìƒìœ„ 5ê°œë§Œ
        for pattern in patterns:
            title = pattern.format(product=original_product, keyword=keyword)
            if len(title) <= 50:  # 50ì ì œí•œ
                variations.add(title)
    
    return list(variations)[:10]  # ìµœëŒ€ 10ê°œ


def build_ai_prompt(product_titles: List[str], custom_prompt: Optional[str] = None) -> str:
    """
    AI ë¶„ì„ìš© í”„ë¡¬í”„íŠ¸ ìƒì„±
    
    Args:
        product_titles: ë¶„ì„í•  ìƒí’ˆëª… ë¦¬ìŠ¤íŠ¸
        custom_prompt: ì‚¬ìš©ì ì •ì˜ í”„ë¡¬í”„íŠ¸ (Noneì´ë©´ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©)
        
    Returns:
        str: ì™„ì„±ëœ í”„ë¡¬í”„íŠ¸
    """
    # ìƒí’ˆëª… ëª©ë¡ í…ìŠ¤íŠ¸ ìƒì„±
    titles_text = "\n".join([f"- {title}" for title in product_titles])
    
    if custom_prompt:
        # ê³µìš© ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ + ì‚¬ìš©ì ì •ì˜ í”„ë¡¬í”„íŠ¸ + ìƒí’ˆëª… ëª©ë¡
        return f"{SYSTEM_PROMPT}\n\n{custom_prompt}\n\nìƒí’ˆëª… ëª©ë¡:\n{titles_text}"
    else:
        # ê³µìš© ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ + ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ + ìƒí’ˆëª… ëª©ë¡
        return f"{SYSTEM_PROMPT}\n\n{DEFAULT_AI_PROMPT}\n\nìƒí’ˆëª… ëª©ë¡:\n{titles_text}"


def parse_ai_keywords_response(ai_response: str) -> List[str]:
    """
    AI ì‘ë‹µì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
    
    Args:
        ai_response: AIê°€ ë°˜í™˜í•œ í…ìŠ¤íŠ¸
        
    Returns:
        List[str]: ì¶”ì¶œëœ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
    """
    # ì‰¼í‘œë¡œ êµ¬ë¶„ëœ í‚¤ì›Œë“œ ì¶”ì¶œ
    keywords = []
    
    # ì¤„ë°”ê¿ˆìœ¼ë¡œ ë‚˜ëˆ„ê³  ê° ì¤„ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
    lines = ai_response.strip().split('\n')
    
    for line in lines:
        line = line.strip()
        if not line or line.startswith('#') or line.startswith('-'):
            continue
            
        # ì‰¼í‘œë¡œ êµ¬ë¶„
        if ',' in line:
            parts = line.split(',')
            for part in parts:
                keyword = part.strip()
                # "+" ê¸°í˜¸ ì œê±° (ì˜ˆ: "ê°•ì•„ì§€+ì˜¤ë˜ë¨¹ëŠ”+ê°œê»Œ" -> "ê°•ì•„ì§€ì˜¤ë˜ë¨¹ëŠ”ê°œê»Œ")
                keyword = keyword.replace('+', '')
                if keyword and len(keyword) >= 2:
                    keywords.append(keyword)
        else:
            # ì‰¼í‘œê°€ ì—†ìœ¼ë©´ ì „ì²´ë¥¼ í•˜ë‚˜ì˜ í‚¤ì›Œë“œë¡œ
            line = line.replace('+', '')  # "+" ê¸°í˜¸ ì œê±°
            if len(line) >= 2:
                keywords.append(line)
    
    # ì¤‘ë³µ ì œê±° (ìˆœì„œ ìœ ì§€)
    unique_keywords = []
    seen = set()
    
    for keyword in keywords:
        keyword_lower = keyword.lower().strip()
        if keyword_lower not in seen:
            seen.add(keyword_lower)
            unique_keywords.append(keyword.strip())
    
    return unique_keywords


def filter_keywords_by_search_volume(keywords: List[KeywordBasicData], min_volume: int = 100) -> List[KeywordBasicData]:
    """
    ê²€ìƒ‰ëŸ‰ ê¸°ì¤€ìœ¼ë¡œ í‚¤ì›Œë“œ í•„í„°ë§
    
    Args:
        keywords: í‚¤ì›Œë“œ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
        min_volume: ìµœì†Œ ì›”ê°„ ê²€ìƒ‰ëŸ‰
        
    Returns:
        List[KeywordBasicData]: í•„í„°ë§ëœ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
    """
    filtered = [kw for kw in keywords if kw.search_volume >= min_volume]
    
    # ê²€ìƒ‰ëŸ‰ ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ ì •ë ¬
    filtered.sort(key=lambda x: x.search_volume, reverse=True)
    
    return filtered


def filter_keywords_by_category(keywords: List[KeywordBasicData], target_category: str) -> List[KeywordBasicData]:
    """
    ì¹´í…Œê³ ë¦¬ ê¸°ì¤€ìœ¼ë¡œ í‚¤ì›Œë“œ í•„í„°ë§ (1ë‹¨ê³„ì—ì„œ ì„ íƒí•œ ì¹´í…Œê³ ë¦¬ì™€ ë§¤ì¹­)
    
    Args:
        keywords: í•„í„°ë§í•  í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
        target_category: 1ë‹¨ê³„ì—ì„œ ì‚¬ìš©ìê°€ ì„ íƒí•œ ì¹´í…Œê³ ë¦¬
        
    Returns:
        List[KeywordBasicData]: ë§¤ì¹­ë˜ëŠ” ì¹´í…Œê³ ë¦¬ì˜ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
    """
    if not keywords or not target_category:
        return keywords
    
    # % ë¶€ë¶„ ì œê±°
    target_clean = target_category.split('(')[0].strip() if '(' in target_category else target_category.strip()
    
    # ë””ë²„ê¹…ìš© ë¡œê·¸
    from src.foundation.logging import get_logger
    logger = get_logger("features.naver_product_title_generator.engine_local")
    logger.info(f"ğŸ¯ í•„í„°ë§ ëŒ€ìƒ ì¹´í…Œê³ ë¦¬: '{target_clean}'")
    
    filtered = []
    for kw in keywords:
        if not kw.category:
            logger.debug(f"  âŒ '{kw.keyword}' - ì¹´í…Œê³ ë¦¬ ì—†ìŒ")
            continue
            
        # í‚¤ì›Œë“œ ì¹´í…Œê³ ë¦¬ë„ % ë¶€ë¶„ ì œê±°
        kw_clean = kw.category.split('(')[0].strip() if '(' in kw.category else kw.category.strip()
        
        # ì¹´í…Œê³ ë¦¬ ë§¤ì¹­ ë¡œì§ (ì›ë³¸ ë¬¸ìì—´ë¡œ ë¹„êµ)
        is_match = is_category_match(target_clean, kw_clean)
        logger.info(f"  {'âœ…' if is_match else 'âŒ'} '{kw.keyword}' - '{kw_clean}' {'ë§¤ì¹­!' if is_match else 'ë¶ˆì¼ì¹˜'}")
        
        if is_match:
            filtered.append(kw)
    
    # ê²€ìƒ‰ëŸ‰ ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ ì •ë ¬
    filtered.sort(key=lambda x: x.search_volume, reverse=True)
    
    logger.info(f"ğŸ“Š í•„í„°ë§ ê²°ê³¼: {len(keywords)}ê°œ ì¤‘ {len(filtered)}ê°œ ë§¤ì¹­")
    
    return filtered


def is_category_match(target_category: str, keyword_category: str) -> bool:
    """
    ë‘ ì¹´í…Œê³ ë¦¬ê°€ ë§¤ì¹­ë˜ëŠ”ì§€ í™•ì¸
    
    Args:
        target_category: 1ë‹¨ê³„ ì„ íƒ ì¹´í…Œê³ ë¦¬
        keyword_category: í‚¤ì›Œë“œì˜ ì¹´í…Œê³ ë¦¬
        
    Returns:
        bool: ë§¤ì¹­ ì—¬ë¶€
    """
    if not target_category or not keyword_category:
        return False
    
    # ì†Œë¬¸ìë¡œ ë³€í™˜í•˜ì—¬ ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ì´ ë¹„êµ
    target_lower = target_category.lower()
    keyword_lower = keyword_category.lower()
    
    # ì •í™•íˆ ê°™ì€ ê²½ìš°
    if target_lower == keyword_lower:
        return True
    
    # ì¹´í…Œê³ ë¦¬ ê²½ë¡œ ë¶„ë¦¬ (> ê¸°ì¤€)
    target_parts = [part.strip() for part in target_lower.split('>') if part.strip()]
    keyword_parts = [part.strip() for part in keyword_lower.split('>') if part.strip()]
    
    if not target_parts or not keyword_parts:
        return False
    
    # ë‘ ì¹´í…Œê³ ë¦¬ì˜ ìµœì†Œ ê¸¸ì´ê¹Œì§€ ë¹„êµ (ì „ì²´ ê¹Šì´ ë¹„êµ)
    min_depth = min(len(target_parts), len(keyword_parts))
    
    for i in range(min_depth):
        # ê° ë‹¨ê³„ì—ì„œ ì¼ì¹˜í•˜ì§€ ì•Šìœ¼ë©´ False
        if target_parts[i] != keyword_parts[i]:
            return False
    
    # ëª¨ë“  ë‹¨ê³„ê°€ ì¼ì¹˜í•˜ë©´ True
    return True


def normalize_keyword_for_comparison(keyword: str) -> str:
    """
    í‚¤ì›Œë“œ ì •ê·œí™” - ì¤‘ë³µ ì²´í¬ìš© (ì†Œë¬¸ì ë³€í™˜)
    
    Args:
        keyword: ì›ë³¸ í‚¤ì›Œë“œ
        
    Returns:
        str: ì¤‘ë³µ ì²´í¬ìš© ì •ê·œí™”ëœ í‚¤ì›Œë“œ (ê³µë°± ì œê±°, ì†Œë¬¸ì ë³€í™˜)
    """
    if not keyword:
        return ""
    
    # 1. ì•ë’¤ ê³µë°± ì œê±°
    cleaned = keyword.strip()
    
    # 2. ë‚´ë¶€ ê³µë°± ì œê±° (ë„¤ì´ë²„ APIëŠ” ë„ì–´ì“°ê¸° ì—†ëŠ” í˜•íƒœë¡œë§Œ ì¸ì‹)
    normalized = cleaned.replace(" ", "")
    
    # 3. ì†Œë¬¸ìë¡œ ë³€í™˜ (ì¤‘ë³µ ì²´í¬ìš©)
    normalized = normalized.lower()
    
    return normalized


def normalize_keyword_for_api(keyword: str) -> str:
    """
    í‚¤ì›Œë“œ ì •ê·œí™” - ë„¤ì´ë²„ API í˜¸ì¶œìš© (ê³µë°±/íŠ¹ìˆ˜ë¬¸ì ì œê±°, ëŒ€ë¬¸ì ë³€í™˜)
    
    Args:
        keyword: ì›ë³¸ í‚¤ì›Œë“œ
        
    Returns:
        str: API í˜¸ì¶œìš© ì •ê·œí™”ëœ í‚¤ì›Œë“œ (ê³µë°±/íŠ¹ìˆ˜ë¬¸ì ì œê±°, ëŒ€ë¬¸ì ë³€í™˜)
    """
    if not keyword:
        return ""
    
    # 1. ì•ë’¤ ê³µë°± ì œê±°
    cleaned = keyword.strip()
    
    # 2. ë‚´ë¶€ ê³µë°± ì œê±° (ë„¤ì´ë²„ APIëŠ” ë„ì–´ì“°ê¸° ì—†ëŠ” í˜•íƒœë¡œë§Œ ì¸ì‹)
    normalized = cleaned.replace(" ", "")
    
    # 3. íŠ¹ìˆ˜ë¬¸ì ì œê±° (í•œê¸€, ì˜ì–´, ìˆ«ìë§Œ ìœ ì§€)
    normalized = re.sub(r'[^ê°€-í£a-zA-Z0-9]', '', normalized)
    
    # 4. ëŒ€ë¬¸ìë¡œ ë³€í™˜ (ë„¤ì´ë²„ API ìš”êµ¬ì‚¬í•­)
    normalized = normalized.upper()
    
    return normalized


def deduplicate_keywords(keywords: List[str]) -> List[str]:
    """
    í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ì—ì„œ ì¤‘ë³µ ì œê±°
    "ê°•ì•„ì§€ê°„ì‹"ê³¼ "ê°•ì•„ì§€ ê°„ì‹"ì„ ê°™ì€ í‚¤ì›Œë“œë¡œ ì²˜ë¦¬
    
    Args:
        keywords: ì›ë³¸ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
        
    Returns:
        List[str]: ì¤‘ë³µ ì œê±°ëœ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ (ì›ë³¸ í˜•íƒœ ìœ ì§€)
    """
    if not keywords:
        return []
    
    seen_normalized = set()  # ì •ê·œí™”ëœ í‚¤ì›Œë“œ ì €ì¥ìš©
    unique_keywords = []     # ì›ë³¸ í˜•íƒœì˜ í‚¤ì›Œë“œ ì €ì¥ìš©
    keyword_mapping = {}     # ì •ê·œí™”ëœ í‚¤ì›Œë“œ -> ì›ë³¸ í‚¤ì›Œë“œ ë§¤í•‘
    
    for keyword in keywords:
        if not keyword or not keyword.strip():
            continue
            
        normalized = normalize_keyword_for_comparison(keyword)
        
        if normalized not in seen_normalized:
            seen_normalized.add(normalized)
            # ì›ë³¸ í‚¤ì›Œë“œ í˜•íƒœë¥¼ ë³´ì¡´ (ì²« ë²ˆì§¸ë¡œ ë‚˜ì˜¨ í˜•íƒœ ì‚¬ìš©)
            unique_keywords.append(keyword.strip())
            keyword_mapping[normalized] = keyword.strip()
    
    return unique_keywords


def calculate_keyword_score(keyword_data: KeywordBasicData) -> float:
    """
    í‚¤ì›Œë“œ ì ìˆ˜ ê³„ì‚° (ê²€ìƒ‰ëŸ‰ ê¸°ë°˜)
    
    Args:
        keyword_data: í‚¤ì›Œë“œ ë°ì´í„°
        
    Returns:
        float: í‚¤ì›Œë“œ ì ìˆ˜ (0-100)
    """
    # ê¸°ë³¸ ì ìˆ˜ëŠ” ê²€ìƒ‰ëŸ‰ ê¸°ë°˜
    volume_score = min(keyword_data.search_volume / 1000 * 50, 70)  # ìµœëŒ€ 70ì 
    
    # í‚¤ì›Œë“œ ê¸¸ì´ ë³´ë„ˆìŠ¤ (2-4ê¸€ìê°€ ì ì •)
    length_bonus = 0
    length = len(keyword_data.keyword)
    if 2 <= length <= 4:
        length_bonus = 20
    elif length == 5:
        length_bonus = 10
    elif length == 6:
        length_bonus = 5
    
    total_score = volume_score + length_bonus
    return min(total_score, 100.0)


# Step 4 ìƒí’ˆëª… ìƒì„±ìš© í”„ë¡¬í”„íŠ¸ (ê³ ì • í”„ë¡¬í”„íŠ¸)
PRODUCT_NAME_GENERATION_SYSTEM_PROMPT = """ë‹¹ì‹ ì€ ë„¤ì´ë²„ ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ ìƒí’ˆëª… SEO ìµœì í™” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìê°€ ì œê³µí•˜ëŠ” ì‚¬ìš©í•  í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ì™€ ê·¸ ì¤‘ í•µì‹¬ì´ ë˜ëŠ” í•µì‹¬í‚¤ì›Œë“œ ê·¸ë¦¬ê³  ì„ íƒ ì…ë ¥ í‚¤ì›Œë“œ(ë¸Œëœë“œëª…,ì¬ë£Œ,ìˆ˜ëŸ‰), ìƒìœ„ ìƒí’ˆëª…ì˜ ê¸¸ì´ í†µê³„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì•„ë˜ ê°€ì´ë“œë¼ì¸ì— ë”°ë¼ ë„¤ì´ë²„ ì‡¼í•‘ ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜ì— ìµœì í™”ëœ ìƒí’ˆëª…ì„ ìƒì„±í•˜ê³ , í•´ë‹¹ ìƒí’ˆëª…ì´ ì–´ë–»ê²Œ ìµœì í™”ë˜ì—ˆëŠ”ì§€ ê·¸ ë°©ì•ˆì„ ìƒì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”."""

DEFAULT_PRODUCT_NAME_GENERATION_PROMPT = """[ì‚¬ìš©ì ì…ë ¥ ì •ë³´]
1. ì‚¬ìš©í•  í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸: {selected_keywords}
2. í•µì‹¬ í‚¤ì›Œë“œ: {core_keyword}
3. ì„ íƒ ì…ë ¥ í‚¤ì›Œë“œ: 
   - ë¸Œëœë“œëª…: {brand}
   - ì¬ë£Œ(í˜•íƒœ): {material}
   - ìˆ˜ëŸ‰(ë¬´ê²Œ): {quantity}
4. ìƒìœ„ ìƒí’ˆëª… ê¸¸ì´ í†µê³„ (ê³µë°± í¬í•¨): {length_stats}

[ìƒí’ˆëª… ì¡°í•© ê°€ì´ë“œë¼ì¸ - ë„¤ì´ë²„ SEO ìµœì í™” ì›ì¹™] 
ì•„ë˜ì˜ ë„¤ì´ë²„ SEO ìµœì í™” ì›ì¹™ë“¤ì„ í•µì‹¬ í‚¤ì›Œë“œ ì¡°í•©ì— ì¤‘ì ì„ ë‘ì–´ ì² ì €íˆ ì¤€ìˆ˜í•˜ë©° ìƒí’ˆëª…ì„ ìƒì„±í•´ì£¼ì„¸ìš”.

1. ë¸Œëœë“œëª… ìµœìš°ì„  ë°°ì¹˜ (ê°€ì¥ ì•):
ìƒí’ˆëª…ì˜ ê°€ì¥ ì•ë¶€ë¶„ì—ëŠ” ë¸Œëœë“œëª…ì„ ë°°ì¹˜í•˜ì—¬ ê²€ìƒ‰ ê°€ì¤‘ì¹˜ë¥¼ ìµœëŒ€ë¡œ í™•ë³´í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. ì…ë ¥ëœ ë¸Œëœë“œëª…ì´ ì—†ìœ¼ë©´ ìƒëµ

2. ë©”ì¸ í‚¤ì›Œë“œ ì‹ë³„ ë° êµ¬ì²´ì ì¸ ìƒí’ˆëª… ë°°ì¹˜:
ì œê³µëœ í‚¤ì›Œë“œ ì¤‘ "í•µì‹¬í‚¤ì›Œë“œ"ëŠ” ê·€í•˜ì˜ ìƒí’ˆì„ ê°€ì¥ ì •í™•í•˜ê²Œ ë‚˜íƒ€ë‚´ëŠ” ë©”ì¸ í‚¤ì›Œë“œì…ë‹ˆë‹¤. ì´ì²˜ëŸ¼ ìƒí’ˆì˜ ê°€ì¥ ì¤‘ìš”í•œ íŠ¹ì§•ì´ë‚˜ ìœ í˜•ì„ ë‚˜íƒ€ë‚´ëŠ” í‚¤ì›Œë“œëŠ” ë¸Œëœë“œëª… ë°”ë¡œ ë’¤ì— ì˜¤ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤

3. í‚¤ì›Œë“œ ì¤‘ë³µ ìµœì†Œí™”:
ë°˜ë³µë˜ëŠ” ë‹¨ì–´ëŠ” ìƒí’ˆëª… ë‚´ì—ì„œ í•œ ë²ˆë§Œ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. ë„¤ì´ë²„ ì•Œê³ ë¦¬ì¦˜ì€ ìƒí’ˆëª… ë‚´ì˜ ë‹¨ì–´ë“¤ì„ ë‹¤ì–‘í•˜ê²Œ ì¡°í•©í•˜ì—¬ í‚¤ì›Œë“œë¥¼ ìƒì„±í•˜ë¯€ë¡œ, ê°™ì€ ë‹¨ì–´ë¥¼ ì—¬ëŸ¬ ë²ˆ ì‚¬ìš©í•˜ì§€ ì•Šì•„ë„ ì—¬ëŸ¬ ê²€ìƒ‰ì–´ì— ë…¸ì¶œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤

4. ê´€ë ¨ í‚¤ì›Œë“œì˜ íš¨ê³¼ì ì¸ í†µí•©:
(ì¶”í›„ ì¶”ê°€ ì˜ˆì •)

[ì¶œë ¥ í˜•ì‹]
1. ìµœì í™”ëœ ìƒí’ˆëª…: [ìƒì„±ëœ ìƒí’ˆëª…]
2. ìµœì í™” ì„¤ëª…: ìœ„ì— ì œì‹œëœ ë„¤ì´ë²„ SEO ìµœì í™” ì›ì¹™ì— ë”°ë¼ ì´ ìƒí’ˆëª…ì´ ì–´ë–»ê²Œ ìµœì í™”ë˜ì—ˆëŠ”ì§€ (ì˜ˆ: í‚¤ì›Œë“œ ë°°ì¹˜, ê¸¸ì´, ì¤‘ë³µ ì œê±°, ë„ì–´ì“°ê¸° ì „ëµ ë“±) ìƒì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”. ê° ì›ì¹™ë³„ë¡œ ì ìš©ëœ ë¶€ë¶„ì„ ëª…ì‹œí•˜ë©´ ì¢‹ìŠµë‹ˆë‹¤."""


def generate_product_name_prompt(selected_keywords: list, core_keyword: str, brand: str = None, material: str = None, quantity: str = None, length_stats: str = None) -> str:
    """Step 4 ìƒí’ˆëª… ìƒì„±ìš© í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    # ì„ íƒëœ í‚¤ì›Œë“œë“¤ì„ ì½¤ë§ˆë¡œ êµ¬ë¶„
    keywords_str = ", ".join(selected_keywords) if selected_keywords else "í‚¤ì›Œë“œ ì—†ìŒ"
    
    return DEFAULT_PRODUCT_NAME_GENERATION_PROMPT.format(
        selected_keywords=keywords_str,
        core_keyword=core_keyword,
        brand=brand or "ì§€ì • ì—†ìŒ",
        material=material or "ì§€ì • ì—†ìŒ", 
        quantity=quantity or "ì§€ì • ì—†ìŒ",
        length_stats=length_stats or "í†µê³„ ì •ë³´ ì—†ìŒ"
    )