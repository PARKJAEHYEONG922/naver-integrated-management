"""
ë„¤ì´ë²„ ìƒí’ˆëª… ìƒì„±ê¸° ì„œë¹„ìŠ¤
ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜: ì…ë ¥ ê²€ì¦ â†’ adapters â†’ engine_local â†’ DB/ì—‘ì…€ íŠ¸ë¦¬ê±°
"""
from typing import List, Dict, Optional, Any
from datetime import datetime

from src.foundation.logging import get_logger
from src.toolbox.text_utils import validate_keyword
from .adapters import ProductTitleAdapters
from .models import (
    ProductTitleRepository, AnalysisResult, AnalysisStatus,
    GeneratedTitle, DEFAULT_SEARCH_VOLUME_THRESHOLD, TOP_N_TITLES
)
from .engine_local import (
    rank_generated_titles, generate_title_variations,
    filter_keywords_by_volume, filter_keywords_by_category,
    extract_candidate_keywords, calculate_category_statistics
)

logger = get_logger(__name__)


class ProductTitleService:
    """ë„¤ì´ë²„ ìƒí’ˆëª… ìƒì„±ê¸° ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        self.adapters = ProductTitleAdapters()
        self.repository = ProductTitleRepository()
    
    def validate_inputs(self, brand: str, keyword: str, spec: str) -> None:
        """ì…ë ¥ê°’ ê²€ì¦ (í•µì‹¬ì œí’ˆëª…ë§Œ í•„ìˆ˜)"""
        # í•µì‹¬ì œí’ˆëª…ë§Œ í•„ìˆ˜
        if not keyword.strip():
            raise ValueError("í•µì‹¬ì œí’ˆëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”")
        
        # ì—¬ëŸ¬ í‚¤ì›Œë“œ ê²€ì¦
        keywords = [k.strip() for k in keyword.split(',') if k.strip()]
        if not keywords:
            raise ValueError("ì˜¬ë°”ë¥¸ í•µì‹¬ì œí’ˆëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”")
        
        for kw in keywords:
            if not validate_keyword(kw):
                raise ValueError(f"ì˜¬ë°”ë¥´ì§€ ì•Šì€ í‚¤ì›Œë“œê°€ ìˆìŠµë‹ˆë‹¤: {kw}")
        
        logger.info(f"ì…ë ¥ê°’ ê²€ì¦ ì™„ë£Œ: brand={brand or 'ë¯¸ì„¤ì •'}, keywords={keywords}, spec={spec or 'ë¯¸ì„¤ì •'}")
    
    def analyze_products(
        self,
        brand: str,
        keyword: str,
        spec: str,
        progress_callback=None
    ) -> AnalysisResult:
        """ìƒí’ˆ ë¶„ì„ ì‹¤í–‰"""
        try:
            # ì·¨ì†Œ ì²´í¬ í—¬í¼ í•¨ìˆ˜
            def _emit_progress(progress: int, message: str) -> None:
                if progress_callback and progress_callback(progress, message) is False:
                    raise RuntimeError("ë¶„ì„ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤")
            
            # 1. ì…ë ¥ê°’ ê²€ì¦
            self.validate_inputs(brand, keyword, spec)
            
            _emit_progress(10, "ğŸ“Š ë„¤ì´ë²„ ì‡¼í•‘ì—ì„œ ìƒí’ˆ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
            
            # 2. ì—¬ëŸ¬ í‚¤ì›Œë“œë¡œ ìƒí’ˆ ë°ì´í„° ìˆ˜ì§‘
            keywords = [k.strip() for k in keyword.split(',') if k.strip()]
            all_titles = []
            all_categories = {}
            
            for i, kw in enumerate(keywords):
                _emit_progress(10 + (i * 15) // len(keywords), f"ğŸ“Š '{kw}' ìƒí’ˆ ê²€ìƒ‰ ì¤‘...")
                products = self.adapters.fetch_products(kw)
                titles, categories = self.adapters.extract_product_info(products)
                all_titles.extend(titles)
                
                # ì¹´í…Œê³ ë¦¬ í•©ê³„ ê³„ì‚°
                for cat, count in categories.items():
                    all_categories[cat] = all_categories.get(cat, 0) + count
            
            if not all_titles:
                raise Exception("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤")
            
            _emit_progress(30, f"âœ… {len(all_titles)}ê°œ ìƒí’ˆ ë¶„ì„ ì™„ë£Œ (í‚¤ì›Œë“œ {len(keywords)}ê°œ)")
            
            # 3. engine_localì„ í†µí•´ ì¹´í…Œê³ ë¦¬ í†µê³„ ê³„ì‚°
            main_category, category_ratio = calculate_category_statistics(all_categories, len(all_titles))
            
            _emit_progress(50, "ğŸ¤– AI í‚¤ì›Œë“œ ì¶”ì¶œ ì¤‘...")
            
            # 4. engine_localì„ í†µí•´ í‚¤ì›Œë“œ í›„ë³´ ì¶”ì¶œ
            ai_keywords = extract_candidate_keywords(
                titles=all_titles,
                brand=brand or "",  # ë¸Œëœë“œê°€ ì—†ì„ ìˆ˜ ìˆìŒ
                spec=spec or "",    # ìŠ¤í™ì´ ì—†ì„ ìˆ˜ ìˆìŒ
                main_category=main_category
            )
            
            _emit_progress(70, "ğŸ” ê²€ìƒ‰ëŸ‰ ì¡°íšŒ ì¤‘...")
            
            # 5. adaptersë¥¼ í†µí•´ ê²€ìƒ‰ëŸ‰ ì¡°íšŒ (ì·¨ì†Œ ì²´í¬ í¬í•¨)
            search_volumes = self.adapters.get_keyword_volumes_batch(
                ai_keywords,
                progress_callback=lambda msg: _emit_progress(75, msg),
                cancel_checker=lambda: progress_callback and progress_callback(0, "") is False if progress_callback else False
            )
            
            # 6. engine_localì„ í†µí•´ í•„í„°ë§ (ê²€ìƒ‰ëŸ‰)
            filtered_by_volume = filter_keywords_by_volume(
                ai_keywords, 
                search_volumes, 
                DEFAULT_SEARCH_VOLUME_THRESHOLD
            )
            
            _emit_progress(90, "ğŸ“‚ ì¹´í…Œê³ ë¦¬ ì¼ì¹˜ì„± ê²€ì‚¬ ì¤‘...")
            
            # 7. ì¹´í…Œê³ ë¦¬ ì¼ì¹˜ í•„í„° ì‹¤ì œ ì ìš©
            keyword_categories = self.adapters.get_keyword_categories(filtered_by_volume)
            filtered_keywords = filter_keywords_by_category(
                keywords=filtered_by_volume,
                keyword_categories=keyword_categories,
                target_category=main_category,
                min_match_rate=0.4
            )
            
            # 8. ìµœì¢… ê²°ê³¼ êµ¬ì„±
            analysis_result = AnalysisResult(
                brand=brand,
                keyword=keyword,
                spec=spec,
                main_category=main_category,
                category_ratio=category_ratio,
                final_tokens=filtered_keywords,
                search_volumes={k: search_volumes[k] for k in filtered_keywords},
                status=AnalysisStatus.COMPLETED,
                created_at=datetime.now().isoformat()
            )
            
            # 9. DB ì €ì¥
            analysis_id = self.repository.save_analysis_result(analysis_result)
            
            _emit_progress(100, "âœ… ë¶„ì„ ì™„ë£Œ!")
            
            logger.info(f"ë¶„ì„ ì™„ë£Œ: {analysis_id}, í‚¤ì›Œë“œ {len(filtered_keywords)}ê°œ")
            return analysis_result
            
        except Exception as e:
            logger.error(f"ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
            
            # ì‹¤íŒ¨ ìƒíƒœë¡œ ìµœì†Œ ë ˆì½”ë“œ ì €ì¥ (ì„ íƒì )
            try:
                failed_result = AnalysisResult(
                    brand=brand,
                    keyword=keyword,
                    spec=spec,
                    main_category="",
                    category_ratio=0.0,
                    final_tokens=[],
                    search_volumes={},
                    status=AnalysisStatus.FAILED,
                    created_at=datetime.now().isoformat()
                )
                self.repository.save_analysis_result(failed_result)
                logger.info("ì‹¤íŒ¨ ìƒíƒœ ë ˆì½”ë“œ ì €ì¥ ì™„ë£Œ")
            except Exception as save_error:
                logger.warning(f"ì‹¤íŒ¨ ìƒíƒœ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {save_error}")
            
            raise
    
    def generate_titles(
        self,
        brand: str,
        keyword: str,
        spec: str,
        selected_tokens: List[str],
        search_volumes: Dict[str, int],
        analysis_id: Optional[int] = None
    ) -> List[GeneratedTitle]:
        """ìƒí’ˆëª… ìƒì„±"""
        try:
            logger.info(f"ìƒí’ˆëª… ìƒì„± ì‹œì‘: {len(selected_tokens)}ê°œ í‚¤ì›Œë“œ")
            
            # 1. engine_localì„ í†µí•´ ì œëª© ë³€í˜• ìƒì„±
            title_variations = generate_title_variations(
                brand, keyword, spec, selected_tokens
            )
            
            # 2. engine_localì„ í†µí•´ ì ìˆ˜ ê³„ì‚° ë° ë­í‚¹
            ranked_titles = rank_generated_titles(
                title_variations,
                brand,
                keyword,
                selected_tokens,
                search_volumes
            )
            
            # ìƒìœ„ Nê°œë§Œ ë°˜í™˜
            final_titles = ranked_titles[:TOP_N_TITLES]
            
            # DB ì €ì¥ (analysis_idê°€ ì œê³µëœ ê²½ìš°)
            if analysis_id is not None:
                self.repository.save_generated_titles(analysis_id, final_titles)
                logger.info(f"ìƒì„±ëœ ìƒí’ˆëª… DB ì €ì¥ ì™„ë£Œ: analysis_id={analysis_id}")
            
            logger.info(f"ìƒí’ˆëª… ìƒì„± ì™„ë£Œ: {len(final_titles)}ê°œ")
            return final_titles
            
        except Exception as e:
            logger.error(f"ìƒí’ˆëª… ìƒì„± ì‹¤íŒ¨: {str(e)}")
            raise
    
    def export_results(
        self,
        file_path: str,
        analysis_result: AnalysisResult,
        generated_titles: List[GeneratedTitle] = None
    ) -> None:
        """ê²°ê³¼ë¥¼ ì—‘ì…€ë¡œ ë‚´ë³´ë‚´ê¸°"""
        try:
            # GeneratedTitle ì§ë ¬í™” (property í¬í•¨)
            title_data = None
            if generated_titles:
                title_data = [
                    {
                        "title": title.title,
                        "seo_score": title.seo_score,
                        "estimated_volume": title.estimated_volume,
                        "char_count": title.char_count,  # property ë³´ì¡´
                        "keywords_used": ",".join(title.keywords_used or [])
                    } for title in generated_titles
                ]
            
            self.adapters.export_analysis_to_excel(
                file_path,
                analysis_result.brand,
                analysis_result.keyword,
                analysis_result.spec,
                analysis_result.final_tokens,
                analysis_result.search_volumes,
                {
                    'main_category': analysis_result.main_category,
                    'ratio': analysis_result.category_ratio
                },
                title_data
            )
            
            logger.info(f"ì—‘ì…€ ë‚´ë³´ë‚´ê¸° ì™„ë£Œ: {file_path}")
            
        except Exception as e:
            logger.error(f"ì—‘ì…€ ë‚´ë³´ë‚´ê¸° ì‹¤íŒ¨: {str(e)}")
            raise
    
    def get_recent_analyses(self, limit: int = 10) -> List[Dict[str, Any]]:
        """ìµœê·¼ ë¶„ì„ ì´ë ¥ ì¡°íšŒ"""
        return self.repository.get_recent_analyses(limit)
    
    def get_analysis_detail(self, analysis_id: int) -> Optional[Dict[str, Any]]:
        """ë¶„ì„ ìƒì„¸ ì •ë³´ ì¡°íšŒ"""
        return self.repository.get_analysis_detail(analysis_id)
    


# ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
product_title_service = ProductTitleService()